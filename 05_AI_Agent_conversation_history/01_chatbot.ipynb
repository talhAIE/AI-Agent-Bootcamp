{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4438fe3",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "In this video We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab78715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989b9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(\n",
    "    model=\"llama3-8b-8192\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f05a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 11, 'total_tokens': 37, 'completion_time': 0.041761186, 'prompt_time': 0.004734133, 'queue_time': 0.32961083500000005, 'total_time': 0.046495319}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_0fb809dba3', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--931deb81-294a-4d0c-9f1b-1abf7d91ab0c-0', usage_metadata={'input_tokens': 11, 'output_tokens': 26, 'total_tokens': 37})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
    "model.invoke([HumanMessage(content=\"Hello\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b7ada1",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f7895be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] =ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    model,get_session_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa83931",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"a\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d8f6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello my name is Talha Abbasi and i am learning Agentic Ai\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c6ff35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Talha Abbasi! Congratulations on starting your journey to learn about Agent-based AI. That's a fascinating field!\\n\\nCan you tell me a bit more about what sparked your interest in Agentic AI? Are you looking to apply it to a specific problem or industry, or is it more of a general interest in AI and its applications?\\n\\nBy the way, have you started with any specific resources or courses to learn about Agentic AI? I'd be happy to help you with any questions or provide recommendations if you need them!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73ff67ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello my name is Talha Abbasi and i am learning Agentic Ai', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, Talha Abbasi! Congratulations on starting your journey to learn about Agent-based AI. That's a fascinating field!\\n\\nCan you tell me a bit more about what sparked your interest in Agentic AI? Are you looking to apply it to a specific problem or industry, or is it more of a general interest in AI and its applications?\\n\\nBy the way, have you started with any specific resources or courses to learn about Agentic AI? I'd be happy to help you with any questions or provide recommendations if you need them!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 25, 'total_tokens': 136, 'completion_time': 0.166400872, 'prompt_time': 0.010643316, 'queue_time': 0.419479883, 'total_time': 0.177044188}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_0fb809dba3', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d89af901-7746-42ed-a58c-026c063d2231-0', usage_metadata={'input_tokens': 25, 'output_tokens': 111, 'total_tokens': 136})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history('chat1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what i am doing?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "697a282a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're currently learning about Agent-based AI! That's a great topic.\\n\\nCan you tell me more about what you're doing specifically? Are you:\\n\\n1. Following online courses or tutorials?\\n2. Reading books or research papers on the subject?\\n3. Working on a project that involves agent-based AI?\\n4. Trying to build a specific application or model using agent-based AI?\\n\\nSharing what you're doing will help me better understand your goals and offer more targeted support and guidance.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "422c04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2={\"configurable\":{\"session_id\":\"chat2\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48596d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems like you're asking me what you're doing. Am I correct?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what i am doing?\")],\n",
    "    config=config2\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b034b9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let me check... Ah yes! You asked me \"what i am doing?\"'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what i asked you before\")],\n",
    "    config=config2\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa2125aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','Your are helpful assistant answer any query in language {language}'),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e8bb310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='مرحباً، تالہ عباسی! خوش آمدید! (Merhaba, Talha Abbasi! Khush ameedeed!) Nice to meet you, Talha Abbasi! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 34, 'total_tokens': 84, 'completion_time': 0.036520969, 'prompt_time': 0.012438086, 'queue_time': 0.6162940640000001, 'total_time': 0.048959055}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_5b339000ab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a2fb3f54-43b5-47f4-84fb-200abec1b41f-0', usage_metadata={'input_tokens': 34, 'output_tokens': 50, 'total_tokens': 84})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Helo my name is Talha Abbadi\")],\n",
    "        \"language\":\"Urdu\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92956bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,get_session_history,\n",
    "    input_messages_key='messages'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd8c8035",
   "metadata": {},
   "outputs": [],
   "source": [
    "config3={\"configurable\":{\"session_id\":\"chat3\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee3a2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"my name is Talha Abbasi\")],\n",
    "    \"language\":\"english\"},\n",
    "    config=config3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2250b5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Talha Abbasi! I'm happy to have you as a part of our conversation.\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e2d636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"what is my name\")],\n",
    "    \"language\":\"english\"},\n",
    "    config=config3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3bf942b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I remember! Your name is Talha Abbasi!'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e568cf2",
   "metadata": {},
   "source": [
    "# Managing Conversational History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38dd192",
   "metadata": {},
   "source": [
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in. \n",
    "\n",
    "<b>'trim_messages'</b> helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0727ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage,trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=100,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4c23223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"you're a good assistant, you always respond with a joke.\"),\n",
    "    HumanMessage(\"i wonder why it's called langchain\"),\n",
    "    AIMessage(\n",
    "        'Well, I guess they thought \"WordRope\" and \"SentenceString\" just didn\\'t have the same ring to it!'\n",
    "    ),\n",
    "    HumanMessage(\"and who is harrison chasing anyways\"),\n",
    "    AIMessage(\n",
    "        \"Hmmm let me think.\\n\\nWhy, he's probably chasing after the last cup of coffee in the office!\"\n",
    "    ),\n",
    "    HumanMessage(\"what do you call a speechless parrot\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fada8220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant, you always respond with a joke.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"i wonder why it's called langchain\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Well, I guess they thought \"WordRope\" and \"SentenceString\" just didn\\'t have the same ring to it!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='and who is harrison chasing anyways', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hmmm let me think.\\n\\nWhy, he's probably chasing after the last cup of coffee in the office!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what do you call a speechless parrot', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cdef1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(\n",
    "        messages=itemgetter(\"messages\")| trimmer)| prompt | model\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "527ad7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're referring to Harrison Ford, right?\\n\\nWell, I think Harrison Ford is probably chasing after his next great adventure... or maybe just trying to navigate his way out of a Star Wars plot twist!\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"who is harrison\")],\n",
    "    \"language\": \"english\"\n",
    "}).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a72d6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets wrap it with message history\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,get_session_history,\n",
    "    input_messages_key='messages'\n",
    ")\n",
    "config6={\"configurable\":{\"session_id\":\"chat7\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ada35054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re referring to Harrison Ford\\'s character, Indiana Jones, and his infamous chase in the movie Raiders of the Lost Ark!\\n\\nBut, to answer your original question, Harrison Ford\\'s character in the movie \"Blade Runner\" is Rick Deckard, and he\\'s chasing after... (drumroll please)... Replicants!'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\n",
    "    \"messages\": messages + [HumanMessage(content=\"who is harrison\")],\n",
    "    \"language\": \"english\"\n",
    "    },\n",
    "    config=config6\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06bd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
