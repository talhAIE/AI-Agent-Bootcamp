{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fafb3f",
   "metadata": {},
   "source": [
    "# simple GenAI app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2478d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]= os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89382453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# data ingestion\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader= WebBaseLoader(web_path=\"https://python.langchain.com/docs/versions/v0_3/\")\n",
    "doc=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c749b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02fa7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text splitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "split_doc=text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8014938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6794c12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2bd4f8cd7f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding and vector store\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings=OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "db=FAISS.from_documents(split_doc,embeddings)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7f5bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='96ffd351-40ce-42d0-9f63-93af76c83b8a', metadata={'source': 'https://python.langchain.com/docs/versions/v0_3/', 'title': 'LangChain v0.3 | ðŸ¦œï¸ðŸ”— LangChain', 'description': 'Last updated: 09.16.24', 'language': 'en'}, page_content=\"Last updated: 09.16.24\\nWhat's changed\\u200b\"),\n",
       " Document(id='29dc4041-c432-4494-b15b-9fa130d8be90', metadata={'source': 'https://python.langchain.com/docs/versions/v0_3/', 'title': 'LangChain v0.3 | ðŸ¦œï¸ðŸ”— LangChain', 'description': 'Last updated: 09.16.24', 'language': 'en'}, page_content='Added utilities for interacting with chat models: universal model constructor, rate limiter, message utilities,\\nAdded the ability to dispatch custom events.\\nRevamped integration docs and API reference. Read more here.\\nMarked as deprecated a number of legacy chains and added migration guides for all of them. These are slated for removal in langchain 1.0.0. See the deprecated chains and associated migration guides here.'),\n",
       " Document(id='c43ab518-3e1a-4497-9522-19d27e6ca333', metadata={'source': 'https://python.langchain.com/docs/versions/v0_3/', 'title': 'LangChain v0.3 | ðŸ¦œï¸ðŸ”— LangChain', 'description': 'Last updated: 09.16.24', 'language': 'en'}, page_content=\"How to update your code\\u200b\\nIf you're using langchain / langchain-community / langchain-core 0.0 or 0.1, we recommend that you first upgrade to 0.2.\\nIf you're using langgraph, upgrade to langgraph>=0.2.20,<0.3. This will work with either 0.2 or 0.3 versions of all the base packages.\\nHere is a complete list of all packages that have been released and what we recommend upgrading your version constraints to.\\nAny package that now requires langchain-core 0.3 had a minor version bump.\"),\n",
       " Document(id='3b93a38d-ba79-44e3-b6c8-76fe70395eee', metadata={'source': 'https://python.langchain.com/docs/versions/v0_3/', 'title': 'LangChain v0.3 | ðŸ¦œï¸ðŸ”— LangChain', 'description': 'Last updated: 09.16.24', 'language': 'en'}, page_content='All packages have been upgraded from Pydantic 1 to Pydantic 2 internally. Use of Pydantic 2 in user code is fully supported with all packages without the need for bridges like langchain_core.pydantic_v1 or pydantic.v1.\\nPydantic 1 will no longer be supported as it reached its end-of-life in June 2024.\\nPython 3.8 will no longer be supported as its end-of-life is October 2024.\\n\\nThese are the only breaking changes.\\nWhatâ€™s new\\u200b\\nThe following features have been added during the development of 0.2.x:')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query from a vector store db\n",
    "query=\"Whats changes in v0.3\"\n",
    "result=db.similarity_search(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed82cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Last updated: 09.16.24\\nWhat's changed\\u200b\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c24efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Added utilities for interacting with chat models: universal model constructor, rate limiter, message utilities,\\nAdded the ability to dispatch custom events.\\nRevamped integration docs and API reference. Read more here.\\nMarked as deprecated a number of legacy chains and added migration guides for all of them. These are slated for removal in langchain 1.0.0. See the deprecated chains and associated migration guides here.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb539b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm=ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda2283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='Answer the follwing question {input} based only on provided context:\\n    <context> \\n    {context}\\n    </context>\\n    '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002BDD41C8830>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002BDD41C8AD0>, root_client=<openai.OpenAI object at 0x000002BDD40CED50>, root_async_client=<openai.AsyncOpenAI object at 0x000002BDD40CF390>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Retrieval Chain, Document Chain \n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the follwing question  based only on provided context:\n",
    "    <context> \n",
    "    {context}\n",
    "    </context>\n",
    "    queston: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "document_chain= create_stuff_documents_chain(llm,prompt)\n",
    " # will responsible to provide context to the prompt\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ee9358f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'input'}.  Expected: ['context', 'input'] Received: ['context']\\nNote: if you intended {input} to be part of the string and not a variable, please escape it with double curly braces like: '{{input}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdocument_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mresult\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\AgenticAIBootcamp\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5431\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5429\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5430\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\AgenticAIBootcamp\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\AgenticAIBootcamp\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:216\u001b[39m, in \u001b[36mBasePromptTemplate.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tags:\n\u001b[32m    215\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] = config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[38;5;28mself\u001b[39m.tags\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\AgenticAIBootcamp\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\AgenticAIBootcamp\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\AgenticAIBootcamp\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:189\u001b[39m, in \u001b[36mBasePromptTemplate._format_prompt_with_error_handling\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) -> PromptValue:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     _inner_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_prompt(**_inner_input)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\AgenticAIBootcamp\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:183\u001b[39m, in \u001b[36mBasePromptTemplate._validate_input\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    177\u001b[39m     example_key = missing.pop()\n\u001b[32m    178\u001b[39m     msg += (\n\u001b[32m    179\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m to be part of the string\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    182\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    184\u001b[39m         create_message(message=msg, error_code=ErrorCode.INVALID_PROMPT_INPUT)\n\u001b[32m    185\u001b[39m     )\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[31mKeyError\u001b[39m: \"Input to ChatPromptTemplate is missing variables {'input'}.  Expected: ['context', 'input'] Received: ['context']\\nNote: if you intended {input} to be part of the string and not a variable, please escape it with double curly braces like: '{{input}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "document_chain.invoke({\n",
    "    \"context\":result\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7abc379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Chain\n",
    "# input-> Retriever-->vectorstore->similarity search->document\n",
    "retriever=db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "129f8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68d799d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002BD4F8CD7F0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='Answer the follwing question {input} based only on provided context:\\n    <context> \\n    {context}\\n    </context>\\n    '), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002BDD41C8830>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002BDD41C8AD0>, root_client=<openai.OpenAI object at 0x000002BDD40CED50>, root_async_client=<openai.AsyncOpenAI object at 0x000002BDD40CF390>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be5c4197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The latest version of LangChain is version 0.3. Some improvements in this version include the ability to automatically update deprecated imports using the langchain-cli, compatibility with both langchain-core 0.2 and 0.3, and minor version bumps for packages that now require langchain-core 0.3.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the response from the LLM\n",
    "response=retriever_chain.invoke({\n",
    "    \"input\":\"what is the latest version of langchain and what improvements are in it\"\n",
    "})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b38782d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the latest version of langchain and what improvements are in it',\n",
       " 'context': [Document(id='111ca602-0e2d-4ffe-bc5a-550d924c336e', metadata={'source': 'https://python.langchain.com/docs/versions/v0_3/', 'title': 'LangChain v0.3 | ðŸ¦œï¸ðŸ”— LangChain', 'description': 'Last updated: 09.16.24', 'language': 'en'}, page_content='LangChain v0.3 | ðŸ¦œï¸ðŸ”— LangChain'),\n",
       "  Document(id='1601590e-f2d9-4dd4-be2b-0953c91e1778', metadata={'source': 'https://python.langchain.com/docs/versions/v0_3/', 'title': 'LangChain v0.3 | ðŸ¦œï¸ðŸ”— LangChain', 'description': 'Last updated: 09.16.24', 'language': 'en'}, page_content='Any package that is now compatible with both langchain-core 0.2 and 0.3 had a patch version bump.\\nYou can use the langchain-cli to update deprecated imports automatically.\\nThe CLI will handle updating deprecated imports that were introduced in LangChain 0.0.x and LangChain 0.1, as\\nwell as updating the langchain_core.pydantic_v1 and langchain.pydantic_v1 imports.\\nBase packages\\u200b'),\n",
       "  Document(id='c43ab518-3e1a-4497-9522-19d27e6ca333', metadata={'source': 'https://python.langchain.com/docs/versions/v0_3/', 'title': 'LangChain v0.3 | ðŸ¦œï¸ðŸ”— LangChain', 'description': 'Last updated: 09.16.24', 'language': 'en'}, page_content=\"How to update your code\\u200b\\nIf you're using langchain / langchain-community / langchain-core 0.0 or 0.1, we recommend that you first upgrade to 0.2.\\nIf you're using langgraph, upgrade to langgraph>=0.2.20,<0.3. This will work with either 0.2 or 0.3 versions of all the base packages.\\nHere is a complete list of all packages that have been released and what we recommend upgrading your version constraints to.\\nAny package that now requires langchain-core 0.3 had a minor version bump.\"),\n",
       "  Document(id='ea926f27-172e-4956-9897-8e8e66f5edd8', metadata={'source': 'https://python.langchain.com/docs/versions/v0_3/', 'title': 'LangChain v0.3 | ðŸ¦œï¸ðŸ”— LangChain', 'description': 'Last updated: 09.16.24', 'language': 'en'}, page_content='to LangChain APIs3. Sub-classing LangChain models4. model_rebuild()Migrate using langchain-cliInstallationUsageOther optionsCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright Â© 2025 LangChain, Inc.')],\n",
       " 'answer': 'The latest version of LangChain is version 0.3. Some improvements in this version include the ability to automatically update deprecated imports using the langchain-cli, compatibility with both langchain-core 0.2 and 0.3, and minor version bumps for packages that now require langchain-core 0.3.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afdf23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
