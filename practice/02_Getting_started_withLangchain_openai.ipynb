{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5bfb81",
   "metadata": {},
   "source": [
    "# Getting started With Langchain And Open Al\n",
    "In this quickstart we'll see how to:\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and - output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2455f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LaNGCHAIN_API_KEY'] = os.getenv('LaNGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2']=\"true\"\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11476bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader=WebBaseLoader(web_path=\"https://blogs.nvidia.com/blog/what-is-agentic-ai/\")\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9824f99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat Is Agentic AI?\\xa0 | NVIDIA Blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tArtificial Intelligence Computing Leadership from NVIDIA\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch for:\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nToggle Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\nAI\\nData Center\\nDriving\\nGaming\\nPro Graphics\\nRobotics\\nHealthcare\\nStartups\\nAI Podcast\\nNVIDIA Life\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat Is Agentic AI?\\xa0\\n\\n\\n\\t\\t\\t\\tAgentic AI uses sophisticated reasoning and iterative planning to autonomously solve complex, multi-step problems.\\t\\t\\t\\n\\n\\nOctober 22, 2024 by Erik Pounds \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tShare\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n \\n \\n \\nEmail0 \\n\\n\\n  Editor’s note: The name of NIM Agent Blueprints was changed to NVIDIA\\xa0Blueprints in October 2024. All references to the name have been updated in this blog.\\nAI chatbots use generative AI to provide responses based on a single interaction. A person makes a query and the chatbot uses natural language processing to reply.\\nThe next frontier of artificial intelligence is agentic AI, which uses sophisticated reasoning and iterative planning to autonomously solve complex, multi-step problems. And it’s set to enhance productivity and operations across industries.\\nAn AI agent for customer service, for instance, could operate beyond simple question-answering. With agentic AI, it could check a user’s outstanding balance and recommend which accounts could pay it off — all while waiting for the user to make a decision so it could complete the transaction accordingly when prompted.\\nAgentic AI systems ingest vast amounts of data from multiple data sources and third-party applications to independently analyze challenges, develop strategies and execute tasks. Businesses are implementing agentic AI to personalize customer service, streamline software development and even facilitate patient interactions.\\n\\nAgentic AI uses sophisticated reasoning and iterative planning to solve complex, multi-step problems.\\nHow Does Agentic AI Work?\\nAgentic AI uses a four-step process for problem-solving:\\n\\nPerceive: AI agents gather and process data from various sources, such as sensors, databases and digital interfaces. This involves extracting meaningful features, recognizing objects or identifying relevant entities in the environment.\\nReason: A large language model acts as the orchestrator, or reasoning engine, that understands tasks, generates solutions and coordinates specialized models for specific functions like content creation, visual processing or recommendation systems. This step uses techniques like retrieval-augmented generation (RAG) to access proprietary data sources and deliver accurate, relevant outputs.\\nAct: By integrating with external tools and software via application programming interfaces, agentic AI can quickly execute tasks based on the plans it has formulated. Guardrails can be built into AI agents to help ensure they execute tasks correctly. For example, a customer service AI agent may be able to process claims up to a certain amount, while claims above the amount would have to be approved by a human.\\nLearn: Agentic AI continuously improves through a feedback loop, or\\n“data flywheel,” where the data generated from its interactions is fed into the system to enhance models. This ability to adapt and become more effective over time offers businesses a powerful tool for driving better decision-making and operational efficiency.\\n\\nFueling Agentic AI With Enterprise Data\\nAcross industries and job functions, generative AI is transforming organizations by turning vast amounts of data into actionable knowledge, helping employees work more efficiently.\\nAI agents build on this potential by accessing diverse data through accelerated AI query engines, which process, store and retrieve information to enhance generative AI models. A key technique for achieving this is RAG, which allows AI to intelligently retrieve the right information from a broader range of data sources.\\nOver time, AI agents learn and improve by creating a data flywheel, where data generated through interactions is fed back into the system, refining models and increasing their effectiveness.\\nThe end-to-end NVIDIA AI platform, including NVIDIA NeMo microservices for developing custom generative AI applications, provides the ability to manage and access data efficiently, which is crucial for building responsive agentic AI applications.\\nAgentic AI in Action\\nThe potential applications of agentic AI are vast, limited only by creativity and expertise. From simple tasks like generating and distributing content to more complex use cases such as orchestrating enterprise software, AI agents are transforming industries.\\n\\nCustomer Service: AI agents are improving customer support by enhancing self-service capabilities and automating routine communications. Over half of service professionals report significant improvements in customer interactions, reducing response times and boosting satisfaction.\\nThere’s also growing interest in digital humans — AI-powered agents that embody a company’s brand and offer lifelike, real-time interactions to help sales representatives answer customer queries or solve issues directly when call volumes are high.\\nContent Creation: Agentic AI can help quickly create high-quality, personalized marketing content. Generative AI agents can save marketers an average of three hours per content piece, allowing them to focus on strategy and innovation. By streamlining content creation, businesses can stay competitive while improving customer engagement.\\nSoftware Engineering: AI agents are boosting developer productivity by automating repetitive coding tasks. It’s projected that by 2030 AI could automate up to 30% of work hours, freeing developers to focus on more complex challenges and drive innovation.\\nHealthcare: For doctors analyzing vast amounts of medical and patient data, AI agents can distill critical information to help them make better-informed care decisions. Automating administrative tasks and capturing clinical notes in patient appointments reduces the burden of time-consuming tasks, allowing doctors to focus on developing a doctor-patient connection.\\nAI agents can also provide 24/7 support, offering information on prescribed medication usage, appointment scheduling and reminders, and more to help patients adhere to treatment plans.\\nVideo analytics: Enterprises and public sector organizations around the world are developing video analytics AI agents to boost the capabilities of workforces that rely on visual information from a growing number of devices — including cameras, IoT sensors and vehicles. Video analytics AI agents can analyze large amounts of live or archived videos, request tasks via natural language and perform complex operations like video search, summarization and visual question-answering. These agents can also be used to deliver anomaly alerts, draft incident reports, improve quality control through visual inspection and enhance predictive maintenance.\\nHow to Get Started\\nWith its ability to plan and interact with a wide variety of tools and software, agentic AI marks the next chapter of artificial intelligence, offering the potential to enhance productivity and revolutionize the way organizations operate.\\nTo accelerate the adoption of generative AI-powered applications and agents, NVIDIA Blueprints provide sample applications, reference code, sample data, tools and comprehensive documentation.\\nNVIDIA partners including Accenture are helping enterprises use agentic AI with solutions built with NVIDIA Blueprints.\\nVisit ai.nvidia.com to learn more about the tools and software NVIDIA offers to help enterprises build their own AI agents.\\xa0\\n\\n\\nCategories: Explainer | Generative AITags: Artificial Intelligence | NVIDIA Blueprints \\n\\n\\n \\n\\n\\n\\n\\nAll NVIDIA News \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tMaking Safer Spaces: NVIDIA and Partners Bring Physical AI to Cities and Industrial Infrastructure\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tNVIDIA Research Shapes Physical AI\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tCrowdStrike, Uber, Zoom Among Industry Pioneers Building Smarter Agents With NVIDIA Nemotron and Cosmos Reasoning Models for Enterprise and Physical AI Applications\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tMini Footprint, Mighty AI: NVIDIA Blackwell Architecture Powers AI Acceleration in Compact Workstations\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tAmazon Devices & Services Achieves Major Step Toward Zero-Touch Manufacturing With NVIDIA AI and Digital Twins\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\nPost navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCorporate Information\\nAbout NVIDIA\\nCorporate Overview\\nTechnologies\\nNVIDIA Research\\nInvestors\\nSocial Responsibility\\nNVIDIA Foundation\\n \\n\\nGet Involved\\nForums\\nCareers\\nDeveloper Home\\nJoin the Developer Program\\nNVIDIA Partner Network\\nNVIDIA Inception\\nResources for Venture Capitalists\\nVenture Capital (NVentures)\\nTechnical Training\\nTraining for IT Professionals\\nProfessional Services for Data Science\\n \\n\\nNews & Events\\nNewsroom\\nNVIDIA Blog\\nNVIDIA Technical Blog\\nWebinars\\nStay Informed\\nEvents Calendar\\nNVIDIA GTC\\nNVIDIA On-Demand\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tExplore our regional blogs and other social networks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPrivacy Policy\\nManage My Privacy\\nLegal\\nAccessibility\\nProduct Security\\nContact\\n \\n\\t\\t\\tCopyright © 2025 NVIDIA Corporation\\t\\t\\n\\n\\n\\n\\n\\t\\t\\t\\tUSA - United States\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\xa0Share This\\xa0Facebook\\xa0LinkedIn\\xa0Email \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare on Mastodon\\n\\n\\nEnter your Mastodon instance URL (optional)\\nShare\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare this Article\\n\\nFriend's Email Address\\n\\n\\n\\nYour Name\\n\\n\\n\\nYour Email Address\\n\\n\\n\\nComments\\n\\n\\n\\n Send Email\\n\\n\\nEmail sent!\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99af0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_text_splitters.character.RecursiveCharacterTextSplitter at 0x2175d3a5fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=20)\n",
    "splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa20ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs=splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6fe9b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vs=FAISS.from_documents(split_docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f56eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documet chain and retriever chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the following questions only based on context provided.\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    question: {input}\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b4ad0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(\n",
    "    model='gpt-3.5-turbo',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5690e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document chain : To give context to the prompt and get response from the llm\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf2ed89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
      "  context: RunnableLambda(format_docs)\n",
      "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
      "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='Answer the following questions only based on context provided.\\n    <context>\\n    {context}\\n    </context>\\n    question: {input}\\n    '), additional_kwargs={})])\n",
      "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000217091D6F90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000217091D7620>, root_client=<openai.OpenAI object at 0x000002170B108410>, root_async_client=<openai.AsyncOpenAI object at 0x000002170B1091D0>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
      "| StrOutputParser() kwargs={} config={'run_name': 'stuff_documents_chain'} config_factories=[]\n"
     ]
    }
   ],
   "source": [
    "print(document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae2bfe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriver chain to get the response from the vector store\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retriever=vs.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":3}\n",
    ")\n",
    "\n",
    "retriever_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f56b27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get response from the llm\n",
    "result=retriever_chain.invoke({\n",
    "    \"input\":\"what is the changes in the new version of langchain?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0002214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input', 'context', 'answer'])\n"
     ]
    }
   ],
   "source": [
    "# get keys of dictionary\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c65457c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The changes in the new version of Langchain involve incorporating a large language model as the orchestrator for understanding tasks, generating solutions, and coordinating specialized models for specific functions.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc4dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
